{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /home/ayushk4/.julia/compiled/v1.0/TextAnalysis/5Mwet.ji for TextAnalysis [a2db99b7-8b79-58f8-94bf-bbc811eef33d]\n",
      "└ @ Base loading.jl:1190\n",
      "┌ Warning: Package TextAnalysis does not have Libdl in its dependencies:\n",
      "│ - If you have TextAnalysis checked out for development and have\n",
      "│   added Libdl as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with TextAnalysis\n",
      "└ Loading Libdl into TextAnalysis from project dependency, future warnings for TextAnalysis are suppressed.\n"
     ]
    }
   ],
   "source": [
    "using TextAnalysis, CorpusLoaders, MultiResolutionIterators, LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CorpusLoaders.load(WikiGold())\n",
    "dataset = flatten_levels(dataset, lvls(WikiGold, :document)) |> full_consolidate\n",
    "\n",
    "X = [CorpusLoaders.word.(sent) for sent in dataset]\n",
    "Y = [TextAnalysis.remove_ner_label_prefix.(CorpusLoaders.named_entity.(sent)) for sent in dataset]\n",
    "@assert length.(X) == length.(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "try_outs (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function try_outs(ner_m, x_in, y_in, eval_func)\n",
    "    unique_labels = unique(ner.model.labels)\n",
    "    num_labels = length(unique_labels)\n",
    "    confusion_matrix = zeros(Int, (num_labels, num_labels))\n",
    "\n",
    "    for (x_seq, y_seq) in zip(x_in, y_in)\n",
    "\n",
    "        preds = eval_func(ner_m, x_seq)\n",
    "        length(preds) != length(y_seq) && continue\n",
    "\n",
    "        for (pred, logit) in zip(preds, y_seq)\n",
    "            (logit == \"MISC\" || pred == \"INVALID\") && continue\n",
    "            confusion_matrix[findfirst(x -> x==pred, unique_labels), findfirst(x -> x==logit, unique_labels)] += 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    s1 = sum(confusion_matrix, dims=2)\n",
    "    s2 = sum(confusion_matrix, dims=1)'\n",
    "    dg = diag(confusion_matrix)\n",
    "    s1 = [s1[1:2]..., s1[4:5]...]\n",
    "    s2 = [s2[1:2]..., s2[4:5]...]\n",
    "    dg = [dg[1:2]..., dg[4:5]...]\n",
    "\n",
    "    unique_labels = unique(ner.model.labels)\n",
    "    deleteat!(unique_labels, findfirst(x -> x==\"MISC\", unique_labels))\n",
    "    # Don't count MISC\n",
    "    \n",
    "    f1s = []\n",
    "\n",
    "    for (p, r, d, tag) in zip(s1, s2, dg, unique_labels)\n",
    "        println(\"For tag `$tag`\")\n",
    "        prec = d/p\n",
    "        recall = d/r\n",
    "        f1 = (2 * prec * recall) /(prec + recall)\n",
    "        println(\"The precision is $prec\")\n",
    "        println(\"The recall is $recall\")\n",
    "        println(\"f1 is $f1\")\n",
    "        println()\n",
    "        push!(f1s, f1)\n",
    "    end\n",
    "\n",
    "    a = sum(dg ./ s1) / length(unique_labels)\n",
    "    b = sum(dg ./ s2) / length(unique_labels)\n",
    "    println(\"Overall Micro f1 for NER (excluding MISC) on CoNLL 2003 is \", (2 * a * b)/ (a + b))\n",
    "    println(\"Overall Macro f1 for NER (excluding MISC) on CoNLL 2003 is \", sum(f1s)/ length(f1s))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_ner_tagger (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = NERTagger()\n",
    "\n",
    "function eval_ner_tagger(ner_m, x_seq) \n",
    "    ner_m(x_seq)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For tag `ORG`\n",
      "The precision is 0.7349726775956285\n",
      "The recall is 0.4121552604698672\n",
      "f1 is 0.5281413612565445\n",
      "\n",
      "For tag `O`\n",
      "The precision is 0.9643743088556144\n",
      "The recall is 0.990514489194499\n",
      "f1 is 0.9772696297418036\n",
      "\n",
      "For tag `PER`\n",
      "The precision is 0.8627797408716137\n",
      "The recall is 0.8965728274173806\n",
      "f1 is 0.8793517406962785\n",
      "\n",
      "For tag `LOC`\n",
      "The precision is 0.8078495502861816\n",
      "The recall is 0.68279198341396\n",
      "f1 is 0.7400749063670413\n",
      "\n",
      "Overall Micro f1 for NER (excluding MISC) on CoNLL 2003 is 0.7910397182885844\n",
      "Overall Macro f1 for NER (excluding MISC) on CoNLL 2003 is 0.7812094095154171\n"
     ]
    }
   ],
   "source": [
    "try_outs(ner, X, Y, eval_ner_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_spacy_tagger (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function eval_spacy_tagger(ner_m, x_seq)\n",
    "    preds = String[]\n",
    "    ents = ner_m(join(x_seq, \" \")).ents\n",
    "\n",
    "    idx = 1\n",
    "    i = 1\n",
    "    while i <= length(x_seq)\n",
    "        if idx <= length(ents) && x_seq[i] == tokenize(ents[idx].text)[1]\n",
    "            l = length(tokenize(ents[idx].text))\n",
    "\n",
    "            for k in 1:l\n",
    "                pred = ents[idx].label_\n",
    "                if (pred == \"PERSON\")\n",
    "                    push!(preds, \"PER\")\n",
    "                elseif ( pred == \"LOC\")\n",
    "                    push!(pred == \"GPE\" || preds, \"LOC\")\n",
    "                elseif (pred == \"ORG\")\n",
    "                    push!(preds, \"ORG\")\n",
    "                else\n",
    "                    push!(preds, \"INVALID\")\n",
    "                end\n",
    "            end\n",
    "            i = i + l - 1\n",
    "            idx += 1\n",
    "        else\n",
    "            push!(preds, \"O\")\n",
    "        end\n",
    "        i += 1\n",
    "    end\n",
    "\n",
    "    return preds\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <spacy.lang.en.English object at 0x7ff965d339b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall, WordTokenizers\n",
    "spacy = pyimport(\"spacy\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For tag `ORG`\n",
      "The precision is 0.5066469719350074\n",
      "The recall is 0.5968677494199536\n",
      "f1 is 0.5480692410119841\n",
      "\n",
      "For tag `O`\n",
      "The precision is 0.9679771928661407\n",
      "The recall is 0.9737877676248916\n",
      "f1 is 0.970873786407767\n",
      "\n",
      "For tag `PER`\n",
      "The precision is 0.7230283911671924\n",
      "The recall is 0.7514754098360655\n",
      "f1 is 0.7369774919614149\n",
      "\n",
      "For tag `LOC`\n",
      "The precision is 0.5833333333333334\n",
      "The recall is 0.12944523470839261\n",
      "f1 is 0.21187427240977885\n",
      "\n",
      "Overall Micro f1 for NER (excluding MISC) on CoNLL 2003 is 0.6514780566020529\n",
      "Overall Macro f1 for NER (excluding MISC) on CoNLL 2003 is 0.6169486979477363\n"
     ]
    }
   ],
   "source": [
    "try_outs(nlp, X, Y, eval_spacy_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk_ner (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk = pyimport(\"nltk\")\n",
    "nltk_chunker = nltk.load(nltk.chunk._MULTICLASS_NE_CHUNKER)\n",
    "nltk_ner(x) = nltk_chunker._tagger.tag(nltk.pos_tag((x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_nltk_tagger (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function eval_nltk_tagger(ner_m, x_seq) \n",
    "    obtain_ner(x) = (x[2]) == \"O\" ? \"O\" : (x[2])[3:end]\n",
    "    preds = obtain_ner.(ner_m(x_seq))\n",
    "\n",
    "    for i in eachindex(preds)\n",
    "        preds[i] == \"O\" && continue\n",
    "\n",
    "        if preds[i] == \"PERSON\"\n",
    "            preds[i] = \"PER\"\n",
    "        elseif preds[i] == \"ORGANIZATION\"\n",
    "            preds[i] = \"ORG\"\n",
    "        elseif preds[i] ∈ (\"LOCATION\", \"GPE\")\n",
    "            preds[i] = \"LOC\"\n",
    "        else\n",
    "            preds[i] = \"INVALID\"\n",
    "        end\n",
    "    end\n",
    "    return preds\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For tag `ORG`\n",
      "The precision is 0.6182669789227166\n",
      "The recall is 0.41015018125323666\n",
      "f1 is 0.4931506849315068\n",
      "\n",
      "For tag `O`\n",
      "The precision is 0.9742044869659996\n",
      "The recall is 0.9878730197715829\n",
      "f1 is 0.9809911434276918\n",
      "\n",
      "For tag `PER`\n",
      "The precision is 0.5979284369114878\n",
      "The recall is 0.7772337821297429\n",
      "f1 is 0.6758914316125598\n",
      "\n",
      "For tag `LOC`\n",
      "The precision is 0.6344950848972297\n",
      "The recall is 0.501412429378531\n",
      "f1 is 0.5601577909270218\n",
      "\n",
      "Overall Micro f1 for NER (excluding MISC) on CoNLL 2003 is 0.6871963551740787\n",
      "Overall Macro f1 for NER (excluding MISC) on CoNLL 2003 is 0.6775477627246951\n"
     ]
    }
   ],
   "source": [
    "try_outs(nltk_ner, X, Y, eval_nltk_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
