{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /home/ayushk4/.julia/compiled/v1.0/TextAnalysis/5Mwet.ji for TextAnalysis [a2db99b7-8b79-58f8-94bf-bbc811eef33d]\n",
      "└ @ Base loading.jl:1190\n",
      "┌ Warning: Package TextAnalysis does not have Libdl in its dependencies:\n",
      "│ - If you have TextAnalysis checked out for development and have\n",
      "│   added Libdl as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with TextAnalysis\n",
      "└ Loading Libdl into TextAnalysis from project dependency, future warnings for TextAnalysis are suppressed.\n"
     ]
    }
   ],
   "source": [
    "using TextAnalysis, CorpusLoaders, MultiResolutionIterators, LinearAlgebra, Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9418-element Array{Array{String,1},1}:\n",
       " [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"Location\", \"O\", \"O\", \"O\", \"Person\", \"Person\", \"Person\", \"O\"]                             \n",
       " [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"  …  \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]                                                \n",
       " [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"  …  \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"Location\", \"Timex\", \"O\"]                                     \n",
       " [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"  …  \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]                                                \n",
       " [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"  …  \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]                                                \n",
       " [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"Person\", \"Person\", \"Person\", \"O\"  …  \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"Location\", \"Location\", \"O\", \"O\"]                   \n",
       " [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]                                                                                                     \n",
       " [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]                                                                                                          \n",
       " [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"  …  \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"Location\", \"Location\", \"O\"]                                  \n",
       " [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"Location\", \"O\", \"Location\"  …  \"O\", \"Location\", \"O\", \"O\", \"O\", \"O\", \"Location\", \"O\", \"Timex\", \"O\"]                \n",
       " [\"Organization\", \"Organization\", \"O\", \"O\", \"Timex\", \"O\", \"O\", \"O\", \"O\", \"O\"  …  \"O\", \"O\", \"O\", \"Location\", \"O\", \"O\", \"Location\", \"O\", \"O\", \"O\"]        \n",
       " [\"Location\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"  …  \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"Timex\", \"Timex\", \"O\"]                                 \n",
       " [\"O\", \"O\", \"Location\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]                                                                                                   \n",
       " ⋮                                                                                                                                                      \n",
       " [\"Person\", \"Person\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"  …  \"Location\", \"Location\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]                        \n",
       " [\"Location\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"  …  \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"Timex\", \"Timex\", \"Timex\", \"O\"]                             \n",
       " [\"O\", \"Person\", \"Person\", \"O\", \"Timex\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"Timex\", \"O\", \"O\", \"O\", \"O\", \"O\", \"Timex\", \"Timex\", \"O\"]                         \n",
       " [\"Organization\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"  …  \"O\", \"O\", \"O\", \"O\", \"O\", \"Person\", \"Person\", \"O\", \"O\", \"O\"]                           \n",
       " [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]                                                                                 \n",
       " [\"Location\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]                                                                          \n",
       " [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"Timex\", \"O\"]                                                              \n",
       " [\"Location\", \"O\", \"O\", \"O\", \"O\", \"O\", \"Timex\", \"O\", \"O\", \"O\"  …  \"O\", \"O\", \"O\", \"O\", \"Organization\", \"Organization\", \"Organization\", \"O\", \"Timex\", \"O\"]\n",
       " [\"Location\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"Location\", \"O\"]                                                                                            \n",
       " [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"  …  \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]                                                \n",
       " [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"  …  \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]                                                \n",
       " [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]                                                                                 "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = flatten_levels(collect(CorpusLoaders.load(GMB())) , lvls(GMB, :document)) |> full_consolidate\n",
    "\n",
    "X = [word.(sentence) for sentence in dataset]\n",
    "Y = [CorpusLoaders.named_entity.(sentence) for sentence in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_ner_tagger (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = NERTagger()\n",
    "\n",
    "function eval_ner_tagger(ner_m, x_seq) \n",
    "    ner_m(x_seq)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "try_outs (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function try_outs(ner_m, x_in, y_in, eval_func)\n",
    "    unique_labels = unique(ner.model.labels)\n",
    "    num_labels = length(unique_labels)\n",
    "    confusion_matrix = zeros(Int, (num_labels, num_labels))\n",
    "\n",
    "    for (x_seq, y_seq) in zip(x_in, y_in)\n",
    "        preds = eval_func(ner_m, x_seq)\n",
    "\n",
    "        for (pred, logit) in zip(preds, y_seq)\n",
    "            (logit == \"MISC\" || pred == \"INVALID\") && continue\n",
    "\n",
    "            if(logit == \"O\")\n",
    "                confusion_matrix[findfirst(x -> x==pred, unique_labels), findfirst(x -> x==\"O\", unique_labels)] += 1\n",
    "            elseif(logit == \"Location\")\n",
    "                confusion_matrix[findfirst(x -> x==pred, unique_labels), findfirst(x -> x==\"LOC\", unique_labels)] += 1\n",
    "            elseif(logit == \"Person\")\n",
    "                confusion_matrix[findfirst(x -> x==pred, unique_labels), findfirst(x -> x==\"PER\", unique_labels)] += 1\n",
    "            elseif(logit == \"Organization\")\n",
    "                confusion_matrix[findfirst(x -> x==pred, unique_labels), findfirst(x -> x==\"ORG\", unique_labels)] += 1\n",
    "            else\n",
    "                continue\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "#     print(confusion_matrix)\n",
    "    s1 = sum(confusion_matrix, dims=2)\n",
    "    s2 = sum(confusion_matrix, dims=1)\n",
    "    dg = diag(confusion_matrix)\n",
    "    s1 = [s1[1:2]..., s1[4:5]...]\n",
    "    s2 = [s2[1:2]..., s2[4:5]...]\n",
    "    dg = [dg[1:2]..., dg[4:5]...]\n",
    "\n",
    "    unique_labels = unique(ner.model.labels)\n",
    "    deleteat!(unique_labels, findfirst(x -> x==\"MISC\", unique_labels))\n",
    "    # Don't count MISC\n",
    "    \n",
    "    f1s = []\n",
    "\n",
    "    for (p, r, d, tag) in zip(s1, s2, dg, unique_labels)\n",
    "        println(\"For tag `$tag`\")\n",
    "        prec = d/p\n",
    "        recall = d/r\n",
    "        f1 = (2 * prec * recall) /(prec + recall)\n",
    "        println(\"The precision is $prec\")\n",
    "        println(\"The recall is $recall\")\n",
    "        println(\"f1 is $f1\")\n",
    "        println()\n",
    "        push!(f1s, f1)\n",
    "    end\n",
    "\n",
    "    a = sum(dg ./ s1) / length(unique_labels)\n",
    "    b = sum(dg ./ s2) / length(unique_labels)\n",
    "    println(\"Overall Micro f1 for NER (excluding MISC) on CoNLL 2003 is \", (2 * a * b)/ (a + b))\n",
    "    println(\"Overall Macro f1 for NER (excluding MISC) on CoNLL 2003 is \", sum(f1s)/ length(f1s))\n",
    "    \n",
    "#     a = mean(dg ./ s1)\n",
    "#     b = mean(dg ./ s2)\n",
    "\n",
    "#     println(\"Precision and recall are:\", a, \" \", b)\n",
    "#     println(\"F1 is:\", (2 * a * b) / (a + b))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For tag `ORG`\n",
      "The precision is 0.7026740799576383\n",
      "The recall is 0.38519593613933234\n",
      "f1 is 0.4976094497046968\n",
      "\n",
      "For tag `O`\n",
      "The precision is 0.9789615040286481\n",
      "The recall is 0.974991755523799\n",
      "f1 is 0.9769725972070936\n",
      "\n",
      "For tag `PER`\n",
      "The precision is 0.7854508196721312\n",
      "The recall is 0.8264338076757223\n",
      "f1 is 0.8054213069972682\n",
      "\n",
      "For tag `LOC`\n",
      "The precision is 0.8240566037735849\n",
      "The recall is 0.7900508762012436\n",
      "f1 is 0.8066955266955267\n",
      "\n",
      "Overall Micro f1 for NER (excluding MISC) on CoNLL 2003 is 0.7815047090242612\n",
      "Overall Macro f1 for NER (excluding MISC) on CoNLL 2003 is 0.7716747201511462\n"
     ]
    }
   ],
   "source": [
    "try_outs(ner, X, Y, eval_ner_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_spacy_tagger (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall, WordTokenizers\n",
    "spacy = pyimport(\"spacy\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "function eval_spacy_tagger(ner_m, x_seq)\n",
    "    preds = String[]\n",
    "    ents = ner_m(join(x_seq, \" \")).ents\n",
    "\n",
    "    idx = 1\n",
    "    i = 1\n",
    "    while i <= length(x_seq)\n",
    "        if idx <= length(ents) && x_seq[i] == tokenize(ents[idx].text)[1]\n",
    "            l = length(tokenize(ents[idx].text))\n",
    "\n",
    "            for k in 1:l\n",
    "                pred = ents[idx].label_\n",
    "                if (pred == \"PERSON\")\n",
    "                    push!(preds, \"PER\")\n",
    "                elseif (pred == \"GPE\" ||  pred == \"LOC\")\n",
    "                    push!(preds, \"LOC\")\n",
    "                elseif (pred == \"ORG\")\n",
    "                    push!(preds, \"ORG\")\n",
    "                else\n",
    "                    push!(preds, \"INVALID\")\n",
    "                end\n",
    "            end\n",
    "            i = i + l - 1\n",
    "            idx += 1\n",
    "        else\n",
    "            push!(preds, \"O\")\n",
    "        end\n",
    "        i += 1\n",
    "    end\n",
    "\n",
    "    return preds\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For tag `ORG`\n",
      "The precision is 0.5882756256427837\n",
      "The recall is 0.5323406235458352\n",
      "f1 is 0.5589121407051543\n",
      "\n",
      "For tag `O`\n",
      "The precision is 0.9730422627751332\n",
      "The recall is 0.9826380531721819\n",
      "f1 is 0.9778166164999839\n",
      "\n",
      "For tag `PER`\n",
      "The precision is 0.7275661717236928\n",
      "The recall is 0.7420983318700615\n",
      "f1 is 0.7347604042160166\n",
      "\n",
      "For tag `LOC`\n",
      "The precision is 0.7454957960763379\n",
      "The recall is 0.6581831035701662\n",
      "f1 is 0.6991239048811013\n",
      "\n",
      "Overall Micro f1 for NER (excluding MISC) on CoNLL 2003 is 0.7434068789865743\n",
      "Overall Macro f1 for NER (excluding MISC) on CoNLL 2003 is 0.7426532665755641\n"
     ]
    }
   ],
   "source": [
    "try_outs(nlp, X, Y, eval_spacy_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_nltk_tagger (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk = pyimport(\"nltk\")\n",
    "nltk_chunker = nltk.load(nltk.chunk._MULTICLASS_NE_CHUNKER)\n",
    "nltk_ner(x) = nltk_chunker._tagger.tag(nltk.pos_tag((x)))\n",
    "\n",
    "function eval_nltk_tagger(ner_m, x_seq) \n",
    "    obtain_ner(x) = (x[2]) == \"O\" ? \"O\" : (x[2])[3:end]\n",
    "    preds = obtain_ner.(ner_m(x_seq))\n",
    "\n",
    "    for i in eachindex(preds)\n",
    "        preds[i] == \"O\" && continue\n",
    "\n",
    "        if preds[i] == \"PERSON\"\n",
    "            preds[i] = \"PER\"\n",
    "        elseif preds[i] == \"ORGANIZATION\"\n",
    "            preds[i] = \"ORG\"\n",
    "        elseif preds[i] ∈ (\"LOCATION\", \"GPE\")\n",
    "            preds[i] = \"LOC\"\n",
    "        else\n",
    "            preds[i] = \"INVALID\"\n",
    "        end\n",
    "    end\n",
    "    return preds\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For tag `ORG`\n",
      "The precision is 0.656305114638448\n",
      "The recall is 0.44162587153241356\n",
      "f1 is 0.5279772989270196\n",
      "\n",
      "For tag `O`\n",
      "The precision is 0.984959026738824\n",
      "The recall is 0.9771382151560868\n",
      "f1 is 0.9810330342852588\n",
      "\n",
      "For tag `PER`\n",
      "The precision is 0.5971675845790716\n",
      "The recall is 0.8194774346793349\n",
      "f1 is 0.6908793009284544\n",
      "\n",
      "For tag `LOC`\n",
      "The precision is 0.5963878326996198\n",
      "The recall is 0.7179311133997025\n",
      "f1 is 0.6515395399553455\n",
      "\n",
      "Overall Micro f1 for NER (excluding MISC) on CoNLL 2003 is 0.7235561475388863\n",
      "Overall Macro f1 for NER (excluding MISC) on CoNLL 2003 is 0.7128572935240195\n"
     ]
    }
   ],
   "source": [
    "try_outs(nltk_ner, X, Y, eval_nltk_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
